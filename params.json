{"name":"Machinelearningassignment1","tagline":"machineLearningAssignment1","body":"# Description of the project and my path to the solutions:\r\n\r\n\r\nI made many experiments before being going through the problem.\r\nIn this document I decided to briefly show such experiments (or spikes, or “katas”) to share my learning experiences. After all the way I solved the problem itself was a serie of try and error on real data, and a process of deciding which features to use, trying a method, verifying the error on the the training set, then on the test set, and so on.\r\nI’ll also talk about the issue of the test set later.\r\nPlease note that this is not a report with a lot of numbers and data, but a narrative about the learning experience toward getting some skills on caret, the pitfalls, and the solution found. It was mainly, I have to admit, a serie of try and error until it worked well.\r\n\r\n##The experimentation:\r\n\r\nTo be sure I understood how to use the tools I set some expectation on artificial data, created such artificial data with a well known underlying model, and then verify such expectation.\r\n\r\nArtificial data: houses having a price depending by a linear combination of factors like: number of rooms, location plus a Gaussian distributed random variable with average 0 and with a specified Standard Deviation.\r\n\r\n\r\n\r\n\tcreateDataFrameOfPrices <- function(numbRows) {\r\n\t\r\n\t#creating dataframe \r\n\tcol1 <- c()\r\n\tcol2 <- c()\r\n\tcol3 <- c()\r\n\tcol4 <- c()\r\n\tcol5 <- c()\r\n\tmyDataFrame <- data.frame(col1,col2,col3,col4,col5)\r\n\r\n\tfor (i in 1:numbRows) {\r\n\t\tnumberOfRooms <- randomNumberOfRooms()\r\n\t\tcityCountryOrSea <- randomBooleanThreePositions()\r\n\t\tprice <- housePrice(numberOfRooms,cityCountryOrSea[[1]],cityCountryOrSea[[2]],cityCountryOrSea[[3]])\r\n\t\tnewRow <- append(c(price,numberOfRooms),cityCountryOrSea)\r\n\t\tmyDataFrame <- rbind(myDataFrame,newRow)\r\n\t}\r\n\r\n\tcolnames(myDataFrame) <- c(\"price\",\"numberRooms\",\"city\",\"country\",\"sea\")\r\n\r\n\treturn(myDataFrame)\r\n\t}\r\n\r\n\r\n\r\n\thousePrice <- function(numRooms=2,isCity=TRUE,isCountry=FALSE,isSea=FALSE) {\r\n\tvarianceOfGaussianNoise <- 5\r\n\treturn(numRooms*100+(isCity*0.9+isSea*1.1+isCountry*1)*100 +rnorm(1,0,varianceOfGaussianNoise))\r\n\t}\r\n\r\n\trandomNumberOfRooms <- function() {\r\n\tsample(2:4,size=1)\r\n\t}\r\n\r\n\trandomBooleanThreePositions <- function() {\r\n\tsample(c(TRUE,FALSE,FALSE),size=3)\r\n\t}\r\n\r\n\r\n##Expectation\r\n\r\nGiven that the underlying model is linear, then a linear model in learning will fit well, and, moreover, the error will be a Gaussian distribution, which is the noise that I added.\r\n\r\nIn this way I can create a 1000 rows dataFrame by calling housePrice.\r\ndataFrame <- createDataFrameOfPrices(1000)\r\n\r\nTo get the model I can write:\r\nmodel <- lm(price ~ ., data=dataFrame)\r\n\r\n\r\nSo I can obtain the values of prices predicted on the training data as follow:\r\n\r\npredictions <- predict(model,data=dataFrame)\r\n\r\nget the error as a vector of differences between the predictions and the real prices:\r\n\r\nerror <- predictions - prices$price\r\n\r\nand if I plot the error (on y) respect to the sample (on x)\r\nas follow:\r\nplot(error)\r\n\r\n\r\n\r\nI get something that is equivalent to plotting the error I added to the model\r\nI can generate directly such error using the command\r\n\r\ngaussNoise <- rnorm(1000,0,5)\r\n\r\nand plot it by plot(gaussNoise) it looks statistically indistinguishable from the plot of the error.\r\n\r\nIf I go to the code that generate the prices, and adjust the standard deviation of the gaussian noise from 5 to 10, and then compare\r\nthe error of the learned model to a gaussian noise generated again with a standard deviation of 10, again we see the same picture.\r\n\r\nEven if the noise is 0, then we see that the error is between -1 and 1 in the recall (probably due only to some rounds in calculation).\r\n\r\n---\r\n\r\n\r\nGiven that all the rest is a matter of: deciding what (if) doing some preprocessing, what features to select among the collected data (features that are unrelated to the outcome create noise and complexity for the learning process).\r\n\r\nOf course, it is a matter of experience in using the tools, and possibility to access to the domain knowledge.\r\n\r\nIn my case the knowledge was almost zero, and despite the knowledge domain is important, I concentrated my effort in the search of an acceptable solution with no assumption to the domain and concentrate on just learning the tools provided by Caret.\r\n\r\nNow I noted this difference between the experiments on artificially generated data and this real data:\r\n\r\nI don't know what variables I have to use, and even I don't know their meaning (already talked about the knowledge on the domain)\r\n\r\nMany data are missing (NA)\r\nMany data are potentially useless (and so will generate noise and complexity)\r\nMany data can be used in the training set but may be missing in the test set.\r\n\r\nI expected that any data that is present on the training data, but missing on the test set, will become noise.\r\nSo, given that I know that there must exist a model that work on the test data, I assumed that it worth to take a look on the test data, see which features are actually used there, and use them as a training process on the training data.\r\n\r\nSo, summarizing, I used the columns names that I can see on the tests set which contains actual data, and which looks making sense.\r\n\r\nSuch columns are:\r\n\r\nnum_window,roll_belt,pitch_belt,yaw_belt,total_accel_belt,gyros_belt_x,gyros_belt_y,gyros_belt_z,accel_belt_x,accel_belt_y,accel_belt_z,magnet_belt_x,magnet_belt_y,magnet_belt_z,roll_arm,pitch_arm,yaw_arm,total_accel_arm,gyros_arm_x,gyros_arm_y,gyros_arm_z,accel_arm_x,accel_arm_y,accel_arm_z,magnet_arm_x,magnet_arm_y,magnet_arm_z,roll_dumbbell,pitch_dumbbell,yaw_dumbbell,total_accel_dumbbell,gyros_dumbbell_x,gyros_dumbbell_y,gyros_dumbbell_z,accel_dumbbell_x,accel_dumbbell_y,accel_dumbbell_z,magnet_dumbbell_x,magnet_dumbbell_y,magnet_dumbbell_z,roll_forearm,pitch_forearm,yaw_forearm,total_accel_forearm,gyros_forearm_x,gyros_forearm_y,gyros_forearm_z,accel_forearm_x,accel_forearm_y,accel_forearm_z,magnet_forearm_x,magnet_forearm_y,magnet_forearm_z\r\n\r\nThey contains all numeric data and no NA. Taking a look on them is enough to find it, otherwise there are automated tools for it (hint: help on complete.cases at it).\r\n\r\nI excluded timestamps because I didn’t expect on the first place that the timestamp would make the difference (perhaps if the timestamp were meant to get an information like “how long this exercise has been done, in that case I would consider it, using some preprocessing getting a difference: end time - start time).\r\n\r\nThe template command to get a model is something like:\r\n\r\nmodel <- train(classe ~ num_window+roll_belt+pitch_belt+yaw_belt+total_accel_belt+gyros_belt_x+gyros_belt_y+gyros_belt_z+accel_belt_x+accel_belt_y+accel_belt_z+magnet_belt_x+magnet_belt_y+magnet_belt_z+roll_arm+pitch_arm+yaw_arm+total_accel_arm+gyros_arm_x+gyros_arm_y+gyros_arm_z+accel_arm_x+accel_arm_y+accel_arm_z+magnet_arm_x+magnet_arm_y+magnet_arm_z+roll_dumbbell+pitch_dumbbell+yaw_dumbbell+total_accel_dumbbell+gyros_dumbbell_x+gyros_dumbbell_y+gyros_dumbbell_z+accel_dumbbell_x+accel_dumbbell_y+accel_dumbbell_z+magnet_dumbbell_x+magnet_dumbbell_y+magnet_dumbbell_z+roll_forearm+pitch_forearm+yaw_forearm+total_accel_forearm+gyros_forearm_x+gyros_forearm_y+gyros_forearm_z+accel_forearm_x+accel_forearm_y+accel_forearm_z+magnet_forearm_x+magnet_forearm_y+magnet_forearm_z, method=\"methodname\", data=trainingData)\r\n\r\nwhere methodname is a specific name for a method, each one has some specificity, or requires different parameters.\r\n\r\nI found difficult to test variants of linear model just because they have some troubles when the data are labels like A, B, C, D, E, which are the outome levels.\r\n\r\nFor example, using “glm” method the error message is:\r\n“glm models can only use 2-class outcomes”\r\n\r\nI had, with bad luck, tried to wrap the outcomes in numeric, but I would not recommend it anymore: for example if I map A, B, C, D, E as 1 2 3 4 5 clearly anyone could say, why not 1 2 3 5 8 13? \r\n\r\nMany model (for example a linear model) will not work in this way simply because the sequence of outcomes should respect the linear model as well.\r\n\r\nSo I tried model that work well with labels, and the first one that worked, also with a reasonable computing time, was the randomForest.\r\n\r\nAbout training set and test set.\r\n\r\nIt is possible to use all the dataFrame as a training set, but the lack of a separate test set/validation set, may lead to an overfit.\r\n\r\nThere is a separate test set in this exercise, and it is probably not meant to use as a test set in the training process, but only for the submission.\r\nIn fact it is:\r\n1) small\r\n2) it does not have explicit expected classe value to be compare (unless I want to use the feedback of the submission phase as a way to measure the error on the test set).\r\n\r\nUsing the entire traininData just as an experiment and relying on the test is actually an hazard.\r\nBy the way I made this hazard, in the sense that I tried to train using all the pml-training.csv, verified the error on that dataFrame, and after seeing that the error was zero, I hypothized that if I had an overfit issue, than I would have realized it as a submission error on the test set.\r\n\r\nBy the way, separating the pml-training.csv in a proper training set and test set is easy using the createDataPartition.\r\n\r\n\r\nBy the way, the final solution is based on the following commands:\r\ntrainingData <- read.csv(“pml-training.csv”)\r\n\r\nmodel <- randomForest(classe ~ num_window+roll_belt+pitch_belt+yaw_belt+total_accel_belt+gyros_belt_x+gyros_belt_y+gyros_belt_z+accel_belt_x+accel_belt_y+accel_belt_z+magnet_belt_x+magnet_belt_y+magnet_belt_z+roll_arm+pitch_arm+yaw_arm+total_accel_arm+gyros_arm_x+gyros_arm_y+gyros_arm_z+accel_arm_x+accel_arm_y+accel_arm_z+magnet_arm_x+magnet_arm_y+magnet_arm_z+roll_dumbbell+pitch_dumbbell+yaw_dumbbell+total_accel_dumbbell+gyros_dumbbell_x+gyros_dumbbell_y+gyros_dumbbell_z+accel_dumbbell_x+accel_dumbbell_y+accel_dumbbell_z+magnet_dumbbell_x+magnet_dumbbell_y+magnet_dumbbell_z+roll_forearm+pitch_forearm+yaw_forearm+total_accel_forearm+gyros_forearm_x+gyros_forearm_y+gyros_forearm_z+accel_forearm_x+accel_forearm_y+accel_forearm_z+magnet_forearm_x+magnet_forearm_y+magnet_forearm_z, data=trainigData)\r\n\r\nI tried the randomForest, \r\n\r\nthis is the model I got:\r\n\r\nCall:\r\n randomForest(formula = classe ~ num_window + roll_belt + pitch_belt +      yaw_belt + total_accel_belt + gyros_belt_x + gyros_belt_y +      gyros_belt_z + accel_belt_x + accel_belt_y + accel_belt_z +      magnet_belt_x + magnet_belt_y + magnet_belt_z + roll_arm +      pitch_arm + yaw_arm + total_accel_arm + gyros_arm_x + gyros_arm_y +      gyros_arm_z + accel_arm_x + accel_arm_y + accel_arm_z + magnet_arm_x +      magnet_arm_y + magnet_arm_z + roll_dumbbell + pitch_dumbbell +      yaw_dumbbell + total_accel_dumbbell + gyros_dumbbell_x +      gyros_dumbbell_y + gyros_dumbbell_z + accel_dumbbell_x +      accel_dumbbell_y + accel_dumbbell_z + magnet_dumbbell_x +      magnet_dumbbell_y + magnet_dumbbell_z + roll_forearm + pitch_forearm +      yaw_forearm + total_accel_forearm + gyros_forearm_x + gyros_forearm_y +      gyros_forearm_z + accel_forearm_x + accel_forearm_y + accel_forearm_z +      magnet_forearm_x + magnet_forearm_y + magnet_forearm_z, data = dataFrame) \r\n               Type of random forest: classification\r\n                     Number of trees: 500\r\nNo. of variables tried at each split: 7\r\n\r\n        OOB estimate of  error rate: 0.14%\r\nConfusion matrix:\r\n     A    B    C    D    E  class.error\r\nA 5579    0    0    0    1 0.0001792115\r\nB    4 3792    1    0    0 0.0013168291\r\nC    0    5 3417    0    0 0.0014611338\r\nD    0    0   11 3204    1 0.0037313433\r\nE    0    0    0    4 3603 0.0011089548\r\n\r\n\r\n\r\nthen I calculated the predicted values using\r\npredicted <- predict(model,trainingData)\r\n\r\nOne easy way to find the error on recall (the number of times the predicted class is different from the actual class) is converting both the classe, i.e. the actuals, and the predicted in numeric and then compute their difference.\r\nThe resulting vector will have non zero values for each discrepancy:\r\n\r\nrecallErrors <- as.numeric(predicted) - as.numeric(dataFrame$classe)\r\n\r\nif recallErrors has all zeros, then it means that the recall is perfect.\r\nIt is easy to see that recallErrors has all zeroes.\r\n\r\nIf this perfection is due to overfit, then I would see errors on the test set, but, after the submission, happens that the applying the predict on the test data resulted in no error as well.\r\n\r\n\r\nThis is the result on the test data:\r\n\r\npredict(newModel,testFrame)\r\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \r\n B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B \r\nLevels: A B C D E\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}